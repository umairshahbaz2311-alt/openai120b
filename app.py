"""
OpenAI 120B Advanced - Version Simplifi√©e et Optimis√©e
Interface compl√®te avec g√©n√©ration de code, ex√©cution Python et projets
"""

import os
import streamlit as st
from openai import OpenAI
import time
import json
import datetime
from pathlib import Path
import sys
import io
import traceback
import zipfile
import re
import requests
import pandas as pd
from PIL import Image
import hashlib
from contextlib import redirect_stdout, redirect_stderr
from functools import lru_cache
from typing import Dict, List, Optional, Any
import uuid

# Configuration s√©curis√©e
SECURITY_CONFIG = {
    "max_execution_time": 10,
    "max_memory_mb": 100,
    "allowed_modules": {'math', 'datetime', 'json', 'random', 'time', 're', 'statistics', 'numpy', 'pandas'},
    "blocked_functions": {'exec', 'eval', 'open', '__import__', 'compile', 'memoryview'},
    "max_file_size_mb": 10,
    "max_project_files": 20
}

# Configuration de la page
st.set_page_config(
    page_title="OpenAI 120B Advanced",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# R√©pertoires
BASE_DIR = Path(".")
CONVERSATIONS_DIR = BASE_DIR / "conversations" 
GENERATED_PROJECTS_DIR = BASE_DIR / "generated_projects"
UPLOADS_DIR = BASE_DIR / "uploads"

# Cr√©er les r√©pertoires
for directory in [CONVERSATIONS_DIR, GENERATED_PROJECTS_DIR, UPLOADS_DIR]:
    directory.mkdir(exist_ok=True)

# Fichiers de donn√©es
CHAT_HISTORY_FILE = BASE_DIR / "chat_history.json"
CREDITS_USAGE_FILE = BASE_DIR / "credits_usage.json"

# Initialisation des √©tats de session
def init_session_state():
    defaults = {
        'dark_mode': False,
        'messages': [],
        'session_tokens': 0,
        'session_requests': 0,
        'projects_created': 0,
        'code_executions': 0
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# CSS optimis√©
@st.cache_data
def get_optimized_css(dark_mode: bool) -> str:
    base_styles = """
    <style>
    .stApp { 
        transition: all 0.3s ease;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }
    .main-header {
        font-size: clamp(2rem, 5vw, 3rem);
        font-weight: 800;
        text-align: center;
        margin: 1rem 0 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    .usage-card {
        padding: 1.5rem;
        border-radius: 12px;
        margin: 0.5rem 0;
        text-align: center;
        color: white;
        background: linear-gradient(135deg, #1565C0 0%, #0D47A1 100%);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .feature-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.4rem 0.8rem;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: 600;
        margin: 0.2rem;
        display: inline-block;
        box-shadow: 0 2px 4px rgba(0,0,0,0.2);
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        text-align: center;
        border-left: 4px solid #667eea;
    }
    .code-result {
        background: #f6f8fa;
        border: 1px solid #e1e4e8;
        border-radius: 6px;
        padding: 1rem;
        margin: 1rem 0;
        font-family: 'Fira Code', monospace;
    }
    """
    
    if dark_mode:
        return base_styles + """
        .stApp { 
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%);
            color: #e0e6ed;
        }
        .metric-card {
            background: #16213e;
            color: #e0e6ed;
            border-left-color: #667eea;
        }
        .code-result {
            background: #0d1117;
            border-color: #30363d;
            color: #e6edf3;
        }
        """
    else:
        return base_styles

st.markdown(get_optimized_css(st.session_state.dark_mode), unsafe_allow_html=True)

# Utilitaires
@lru_cache(maxsize=256)
def estimate_tokens(text: str) -> int:
    return max(1, int(len(text.split()) * 1.3))

def secure_hash(data: str) -> str:
    return hashlib.sha256(data.encode()).hexdigest()[:16]

# Gestionnaire de fichiers
def load_json_file(filepath: Path, default=None):
    if filepath.exists():
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erreur lecture {filepath}: {e}")
    return default or {}

def save_json_file(filepath: Path, data):
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except Exception as e:
        st.error(f"Erreur sauvegarde {filepath}: {e}")

# Chargement des donn√©es
def load_chat_history():
    return load_json_file(CHAT_HISTORY_FILE, [])

def save_chat_history():
    save_json_file(CHAT_HISTORY_FILE, st.session_state.messages)

def load_credits_usage():
    return load_json_file(CREDITS_USAGE_FILE, {
        "total_tokens": 0,
        "total_requests": 0,
        "sessions": [],
        "projects_created": 0
    })

def save_credits_usage(data):
    save_json_file(CREDITS_USAGE_FILE, data)

# Ex√©cuteur de code s√©curis√©
class SecureCodeExecutor:
    def __init__(self):
        self.safe_builtins = {
            'abs', 'all', 'any', 'bool', 'dict', 'enumerate', 'filter',
            'float', 'int', 'len', 'list', 'map', 'max', 'min', 'print',
            'range', 'round', 'sorted', 'str', 'sum', 'type', 'zip',
            'set', 'tuple', 'reversed', 'chr', 'ord'
        }
    
    def execute(self, code: str) -> Dict[str, Any]:
        if not code.strip():
            return {"success": False, "output": "", "error": "Code vide"}
        
        # V√©rifications s√©curitaires
        dangerous_patterns = [
            r'\b(exec|eval|compile|__import__)\s*\(',
            r'\bopen\s*\(',
            r'\bfile\s*\(',
            r'subprocess',
            r'os\.(system|popen|remove)',
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, code):
                return {"success": False, "output": "", "error": f"Code dangereux d√©tect√©: {pattern}"}
        
        if len(code) > 10000:
            return {"success": False, "output": "", "error": "Code trop long (max 10000 caract√®res)"}
        
        try:
            # Environnement s√©curis√©
            safe_globals = {
                '__builtins__': {name: getattr(__builtins__, name) 
                               for name in self.safe_builtins if hasattr(__builtins__, name)}
            }
            
            # Modules autoris√©s
            for module in SECURITY_CONFIG['allowed_modules']:
                try:
                    safe_globals[module] = __import__(module)
                    if module == 'numpy':
                        safe_globals['np'] = safe_globals[module]
                    elif module == 'pandas':
                        safe_globals['pd'] = safe_globals[module]
                except ImportError:
                    continue
            
            # Redirection des sorties
            output_buffer = io.StringIO()
            error_buffer = io.StringIO()
            
            try:
                with redirect_stdout(output_buffer), redirect_stderr(error_buffer):
                    exec(code, safe_globals)
                
                output = output_buffer.getvalue()
                error = error_buffer.getvalue()
                
                return {
                    'success': True,
                    'output': output,
                    'error': error if error else None
                }
                
            except Exception as e:
                return {
                    "success": False,
                    "output": "",
                    "error": f"Erreur d'ex√©cution: {str(e)}"
                }
                
        except Exception as e:
            return {"success": False, "output": "", "error": f"Erreur syst√®me: {str(e)}"}

# Gestionnaire de projets
def create_project_structure(project_data: Dict) -> tuple:
    """Cr√©e la structure d'un projet"""
    try:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        project_name = project_data.get('name', 'project').replace(' ', '_').lower()
        project_name = re.sub(r'[^a-z0-9_]', '', project_name)
        
        project_path = GENERATED_PROJECTS_DIR / f"{project_name}_{timestamp}"
        project_path.mkdir(parents=True, exist_ok=True)
        
        created_files = []
        files = project_data.get('files', [])
        
        for file_info in files:
            if isinstance(file_info, dict) and 'name' in file_info and 'content' in file_info:
                file_path = project_path / file_info['name']
                file_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(file_info['content'])
                
                created_files.append(str(file_path.relative_to(GENERATED_PROJECTS_DIR)))
        
        return project_path, created_files
        
    except Exception as e:
        st.error(f"Erreur cr√©ation projet: {e}")
        return None, []

def create_download_zip(project_path: Path) -> Optional[Path]:
    """Cr√©e un ZIP t√©l√©chargeable"""
    try:
        zip_path = project_path.with_suffix('.zip')
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in project_path.rglob('*'):
                if file_path.is_file():
                    arcname = file_path.relative_to(project_path)
                    zipf.write(file_path, arcname)
        return zip_path
    except Exception as e:
        st.error(f"Erreur cr√©ation ZIP: {e}")
        return None

# Gestionnaire de fichiers upload√©s
def handle_file_upload(uploaded_file) -> Optional[str]:
    """Traite un fichier upload√©"""
    if not uploaded_file:
        return None
    
    # V√©rification taille
    if uploaded_file.size > SECURITY_CONFIG['max_file_size_mb'] * 1024 * 1024:
        st.error(f"Fichier trop volumineux (max {SECURITY_CONFIG['max_file_size_mb']}MB)")
        return None
    
    file_ext = uploaded_file.name.split('.')[-1].lower()
    
    try:
        if file_ext in ['txt', 'py', 'js', 'html', 'css', 'md']:
            content = uploaded_file.getvalue().decode('utf-8')
            with st.expander(f"üìÑ {uploaded_file.name}", expanded=False):
                st.code(content[:2000] + ("..." if len(content) > 2000 else ""), language=file_ext)
            return f"Fichier texte '{uploaded_file.name}' analys√© ({len(content)} caract√®res)."
            
        elif file_ext in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
            image = Image.open(uploaded_file)
            st.image(image, caption=uploaded_file.name, width=400)
            return f"Image '{uploaded_file.name}' affich√©e ({image.size[0]}x{image.size[1]}px)."
            
        elif file_ext == 'csv':
            df = pd.read_csv(uploaded_file)
            st.dataframe(df.head(100))
            return f"CSV '{uploaded_file.name}': {len(df)} lignes, {len(df.columns)} colonnes."
            
        else:
            st.info(f"Type de fichier '{file_ext}' non support√© pour pr√©visualisation")
            return f"Fichier '{uploaded_file.name}' upload√©."
            
    except Exception as e:
        st.error(f"Erreur traitement fichier: {e}")
        return None

# Client OpenAI
@st.cache_resource
def init_openai_client(token: str) -> OpenAI:
    return OpenAI(
        base_url="https://router.huggingface.co/v1",
        api_key=token,
        timeout=30.0
    )

# Prompts syst√®me simplifi√©s
def get_system_prompt(mode: str) -> str:
    prompts = {
        "üí¨ Chat": "Tu es un assistant IA avanc√©, serviable et pr√©cis. R√©ponds de mani√®re claire et d√©taill√©e en fran√ßais.",
        
        "üîß Code": """Tu es un expert d√©veloppeur. G√©n√®re du code complet et fonctionnel.

Pour cr√©er des projets, utilise ce format JSON:
```json
{
  "name": "nom_du_projet",
  "description": "Description d√©taill√©e",
  "type": "web|desktop|mobile|api",
  "files": [
    {
      "name": "index.html",
      "content": "<!DOCTYPE html>...",
      "description": "Fichier principal"
    }
  ],
  "installation": "Instructions d'installation",
  "usage": "Instructions d'utilisation"
}
```

R√®gles:
- Code complet et comment√©
- S√©curit√© et bonnes pratiques
- Design moderne et responsive""",
        
        "‚ö° Python": """Tu es un expert Python. √âcris du code ex√©cutable et s√ªr.

Modules disponibles: math, datetime, json, random, time, re, statistics, numpy, pandas.
Utilise print() pour afficher les r√©sultats.
√âvite les op√©rations dangereuses ou non autoris√©es.

Format:
1. Explication du probl√®me
2. Code Python complet et comment√©
3. Exemple d'utilisation si pertinent"""
    }
    return prompts.get(mode, prompts["üí¨ Chat"])

# Extraction des donn√©es
def extract_json_from_response(response: str) -> Optional[Dict]:
    """Extrait JSON de la r√©ponse"""
    try:
        json_pattern = r'```json\s*\n(.*?)\n```'
        matches = re.findall(json_pattern, response, re.DOTALL)
        
        for match in matches:
            try:
                return json.loads(match.strip())
            except json.JSONDecodeError:
                continue
        
        return None
    except:
        return None

def extract_code_blocks(response: str, language: str = "python") -> List[str]:
    """Extrait les blocs de code"""
    pattern = f"```{language}\\s*\\n(.*?)\\n```"
    return re.findall(pattern, response, re.DOTALL)

# Interface principale
def main():
    # Header
    st.markdown('<h1 class="main-header">üß† OpenAI 120B Advanced</h1>', 
                unsafe_allow_html=True)
    
    # Badges de fonctionnalit√©s
    st.markdown("""
    <div style="text-align: center; margin: 2rem 0;">
        <span class="feature-badge">üî• Code Generation</span>
        <span class="feature-badge">‚ö° Python Exec</span>
        <span class="feature-badge">üìé File Upload</span>
        <span class="feature-badge">üåì Dark Mode</span>
        <span class="feature-badge">üíæ Persistent Chat</span>
        <span class="feature-badge">üîí Secure Sandbox</span>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("üéõÔ∏è Centre de Contr√¥le")
        
        # Toggle th√®me
        if st.button("üåì Basculer Th√®me", key="theme_toggle"):
            st.session_state.dark_mode = not st.session_state.dark_mode
            st.rerun()
        
        theme_status = "üåô Mode Sombre" if st.session_state.dark_mode else "‚òÄÔ∏è Mode Clair"
        st.caption(f"Th√®me actuel: {theme_status}")
        
        st.markdown("---")
        
        # Configuration token
        st.subheader("üîê Configuration")
        user_token = st.text_input(
            "Token Hugging Face",
            type="password",
            placeholder="hf_...",
            help="Votre token HF pour acc√©der √† l'API",
            key="hf_token_input"
        )
        
        if not user_token or not user_token.startswith("hf_"):
            st.warning("‚ö†Ô∏è Token HF requis (format: hf_...)")
            st.markdown("""
            **Comment obtenir votre token:**
            1. [Cr√©er un compte HF](https://huggingface.co/join)
            2. Aller dans [Settings > Access Tokens](https://huggingface.co/settings/tokens)
            3. Cr√©er un nouveau token (Read access)
            4. Copier et coller ici
            """)
            st.stop()
        
        st.success("‚úÖ Token d√©tect√©")
        
        # Param√®tres IA
        st.subheader("ü§ñ Param√®tres IA")
        work_mode = st.selectbox(
            "Mode de travail:",
            ["üí¨ Chat", "üîß Code", "‚ö° Python"],
            key="work_mode"
        )
        
        temperature = st.slider("üå°Ô∏è Cr√©ativit√©", 0.1, 1.5, 0.7, 0.1)
        max_tokens = st.slider("üìù Tokens Max", 500, 4000, 2000, 250)
        
        # Options
        st.subheader("‚öôÔ∏è Options")
        auto_execute = st.checkbox("‚ö° Auto-ex√©cution Python", value=True)
        auto_projects = st.checkbox("üìÅ Auto-cr√©ation projets", value=True)
        
        # Upload de fichiers
        st.subheader("üìé Upload Fichiers")
        uploaded_file = st.file_uploader(
            "Choisir un fichier",
            type=['txt', 'py', 'js', 'html', 'css', 'md', 'csv', 'jpg', 'jpeg', 'png', 'pdf'],
            help="Fichiers support√©s: texte, code, images, CSV"
        )
        
        # Statistiques de session
        st.subheader("üìä Session")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Messages", len(st.session_state.messages))
            st.metric("Tokens", st.session_state.session_tokens)
        with col2:
            st.metric("Requ√™tes", st.session_state.session_requests)
            st.metric("Projets", st.session_state.projects_created)
        
        # Actions
        st.subheader("üõ†Ô∏è Actions")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è Reset Chat", type="secondary"):
                st.session_state.messages = []
                save_chat_history()
                st.success("Chat r√©initialis√©!")
                time.sleep(1)
                st.rerun()
        
        with col2:
            if st.button("üíæ Export") and st.session_state.messages:
                export_data = {
                    "messages": st.session_state.messages,
                    "metadata": {
                        "export_date": datetime.datetime.now().isoformat(),
                        "total_messages": len(st.session_state.messages),
                        "session_tokens": st.session_state.session_tokens
                    }
                }
                
                st.download_button(
                    "üì• T√©l√©charger Chat",
                    json.dumps(export_data, indent=2, ensure_ascii=False),
                    file_name=f"chat_export_{int(time.time())}.json",
                    mime="application/json"
                )
    
    # Initialisation du client OpenAI
    try:
        client = init_openai_client(user_token)
        st.success("‚úÖ Client OpenAI initialis√©")
    except Exception as e:
        st.error(f"‚ùå Erreur client: {e}")
        st.stop()
    
    # Chargement de l'historique
    if not st.session_state.messages:
        st.session_state.messages = load_chat_history()
    
    # Gestionneurs
    executor = SecureCodeExecutor()
    
    # Zone de chat
    st.markdown("### üí¨ Chat avec Historique Persistant")
    
    # Affichage des messages
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # R√©sultats d'ex√©cution Python
            if "execution_result" in message:
                result = message["execution_result"]
                with st.expander("‚ö° R√©sultat d'Ex√©cution Python", expanded=True):
                    if result["success"]:
                        if result["output"]:
                            st.success("‚úÖ Ex√©cution r√©ussie")
                            st.code(result["output"], language="text")
                        else:
                            st.info("‚úÖ Code ex√©cut√© sans sortie")
                        if result.get("error"):
                            st.warning(f"‚ö†Ô∏è Avertissements: {result['error']}")
                    else:
                        st.error("‚ùå Erreur d'ex√©cution")
                        st.code(result["error"], language="text")
            
            # Projets cr√©√©s
            if "project_created" in message:
                project_info = message["project_created"]
                with st.expander("üöÄ Projet Cr√©√©", expanded=True):
                    st.success(f"‚úÖ **{project_info['name']}** cr√©√©!")
                    st.markdown(f"**Description:** {project_info['description']}")
                    
                    if project_info.get('files'):
                        st.markdown("**üìÅ Fichiers cr√©√©s:**")
                        for file_path in project_info['files']:
                            st.text(f"üìÑ {file_path}")
    
    # Traitement du fichier upload√©
    file_context = ""
    if uploaded_file:
        with st.spinner("Traitement du fichier..."):
            file_context = handle_file_upload(uploaded_file) or ""
    
    # Zone de saisie
    placeholder_texts = {
        "üí¨ Chat": "Posez votre question...",
        "üîß Code": "D√©crivez l'application √† cr√©er...",
        "‚ö° Python": "D√©crivez le calcul √† effectuer..."
    }
    
    if prompt := st.chat_input(placeholder_texts.get(work_mode, "Votre message...")):
        # Ajouter contexte du fichier si pr√©sent
        full_prompt = f"{prompt}\n\n[Contexte fichier: {file_context}]" if file_context else prompt
        
        # Message utilisateur
        st.session_state.messages.append({"role": "user", "content": full_prompt})
        save_chat_history()
        
        with st.chat_message("user"):
            st.markdown(full_prompt)
        
        # G√©n√©ration de la r√©ponse
        with st.chat_message("assistant"):
            try:
                # Pr√©paration des messages pour l'API
                system_prompt = get_system_prompt(work_mode)
                api_messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": full_prompt}
                ]
                
                # Ajout de l'historique r√©cent (limit√©)
                recent_messages = st.session_state.messages[-6:]
                for msg in recent_messages[:-1]:
                    if len(msg["content"]) < 1500:
                        api_messages.append({
                            "role": msg["role"],
                            "content": msg["content"][:1000] + ("..." if len(msg["content"]) > 1000 else "")
                        })
                
                # Appel API avec retry
                response = None
                with st.spinner("G√©n√©ration de la r√©ponse..."):
                    for attempt in range(3):
                        try:
                            completion = client.chat.completions.create(
                                model="openai/gpt-oss-120b:together",
                                messages=api_messages,
                                max_tokens=max_tokens,
                                temperature=temperature,
                            )
                            response = completion.choices[0].message.content
                            break
                        except Exception as e:
                            if attempt == 2:
                                raise e
                            time.sleep(1)
                
                if not response:
                    response = "‚ùå Erreur: Impossible de g√©n√©rer une r√©ponse"
                
                # Affichage de la r√©ponse
                st.markdown(response)
                
                # Pr√©paration des donn√©es du message
                message_data = {"role": "assistant", "content": response}
                
                # Post-traitement selon le mode
                if work_mode == "‚ö° Python" or auto_execute:
                    # Ex√©cution automatique du code Python
                    python_blocks = extract_code_blocks(response, "python")
                    if python_blocks:
                        st.markdown("---")
                        st.markdown("### ‚ö° Ex√©cution Automatique du Code")
                        
                        for i, code_block in enumerate(python_blocks):
                            with st.expander(f"üêç Code Python {i+1}", expanded=True):
                                st.code(code_block, language="python")
                                
                                with st.spinner("Ex√©cution en cours..."):
                                    result = executor.execute(code_block)
                                
                                message_data["execution_result"] = result
                                
                                if result["success"]:
                                    if result["output"]:
                                        st.success("‚úÖ Ex√©cution r√©ussie")
                                        st.code(result["output"], language="text")
                                    else:
                                        st.info("‚úÖ Code ex√©cut√© sans sortie")
                                    if result.get("error"):
                                        st.warning(f"‚ö†Ô∏è Avertissements: {result['error']}")
                                else:
                                    st.error("‚ùå Erreur d'ex√©cution")
                                    st.code(result["error"], language="text")
                        
                        st.session_state.code_executions += 1
                
                elif work_mode == "üîß Code" or auto_projects:
                    # Cr√©ation automatique de projets
                    project_data = extract_json_from_response(response)
                    if project_data and project_data.get('files'):
                        st.markdown("---")
                        st.markdown("### üöÄ Cr√©ation du Projet")
                        
                        with st.spinner("Cr√©ation du projet..."):
                            project_path, created_files = create_project_structure(project_data)
                        
                        if project_path and created_files:
                            message_data["project_created"] = {
                                "name": project_data.get("name", "Projet Sans Nom"),
                                "description": project_data.get("description", ""),
                                "files": created_files,
                                "path": str(project_path.relative_to(GENERATED_PROJECTS_DIR))
                            }
                            
                            st.success(f"‚úÖ Projet **{project_data.get('name')}** cr√©√©!")
                            
                            # Affichage des fichiers
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**üìÅ Fichiers cr√©√©s:**")
                                for file_path in created_files:
                                    st.text(f"üìÑ {file_path}")
                            
                            with col2:
                                # Bouton de t√©l√©chargement
                                zip_path = create_download_zip(project_path)
                                if zip_path and zip_path.exists():
                                    with open(zip_path, 'rb') as f:
                                        st.download_button(
                                            "üì• T√©l√©charger Projet (ZIP)",
                                            f.read(),
                                            file_name=f"{project_data.get('name', 'project')}.zip",
                                            mime="application/zip"
                                        )
                            
                            st.session_state.projects_created += 1
                
                # Calcul des tokens et co√ªt
                tokens_used = estimate_tokens(response)
                input_tokens = sum(estimate_tokens(msg["content"]) for msg in api_messages)
                total_tokens = tokens_used + input_tokens
                cost_estimate = total_tokens * 0.00075 / 1000  # Estimation du co√ªt
                
                # M√©triques en bas
                st.markdown("---")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.caption(f"üìù {tokens_used} tokens sortie")
                with col2:
                    st.caption(f"üìä {total_tokens} tokens total")
                with col3:
                    st.caption(f"üí∞ ~${cost_estimate:.4f}")
                with col4:
                    st.caption(f"üéØ {work_mode}")
                
                # Mise √† jour des compteurs de session
                st.session_state.session_tokens += total_tokens
                st.session_state.session_requests += 1
                
                # Sauvegarde des statistiques
                credits_data = load_credits_usage()
                credits_data['total_tokens'] = credits_data.get('total_tokens', 0) + total_tokens
                credits_data['total_requests'] = credits_data.get('total_requests', 0) + 1
                save_credits_usage(credits_data)
                
            except Exception as e:
                error_msg = f"‚ùå Erreur: {str(e)}"
                st.error(error_msg)
                message_data = {"role": "assistant", "content": error_msg}
        
        # Sauvegarde du message
        st.session_state.messages.append(message_data)
        save_chat_history()
    
    # Guide d'utilisation si aucun message
    if not st.session_state.messages:
        st.markdown("""
        ## üéØ Guide d'Utilisation OpenAI 120B Advanced
        
        ### üÜï **Fonctionnalit√©s Disponibles**
        - ‚ö° **Ex√©cution Python S√©curis√©e** - Code ex√©cut√© dans un sandbox
        - üöÄ **G√©n√©ration de Projets** - Applications compl√®tes t√©l√©chargeables
        - üíæ **Chat Persistant** - Historique sauvegard√© automatiquement
        - üìé **Upload Fichiers** - Support images, CSV, code
        - üåì **Mode Sombre/Clair** - Interface adaptable
        - üîí **S√©curit√© Renforc√©e** - Validation stricte du code
        
        ### ‚ö° **Exemples Python**
        - *"Analyse ce fichier CSV upload√©"*
        - *"Cr√©e un graphique des donn√©es de vente"*
        - *"Calcule les statistiques de ce dataset: [1,2,3,4,5]"*
        - *"G√©n√®re 10 nombres al√©atoires et calcule leur moyenne"*
        
        ### üîß **Exemples Projets**
        - *"D√©veloppe une todo-list en HTML/CSS/JS"*
        - *"Cr√©e une calculatrice web moderne"*
        - *"G√©n√®re un site portfolio responsive"*
        - *"Fais une API REST Flask simple"*
        
        ### üí¨ **Chat G√©n√©ral**
        - Questions techniques avec contexte
        - Analyse de fichiers upload√©s
        - Explications d√©taill√©es
        - Conseils et recommandations
        
        **üöÄ Commencez par uploader un fichier ou poser une question !**
        """)
    
    # Footer avec statistiques
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("**üß† OpenAI 120B**")
        st.caption("Assistant IA Avanc√©")
    
    with col2:
        st.markdown("**‚ö° Python**")
        st.caption("Ex√©cution s√©curis√©e")
    
    with col3:
        st.markdown("**üöÄ Projets**")
        st.caption(f"{st.session_state.projects_created} cr√©√©s")
    
    with col4:
        st.markdown("**üíæ Session**")
        st.caption(f"{len(st.session_state.messages)} messages")
    
    # Version et informations
    st.markdown(
        f"<div style='text-align: center; color: #666; font-size: 0.8rem; margin-top: 1rem;'>"
        f"üí° Version 4.0 Simplifi√© | Session: {st.session_state.session_tokens} tokens | "
        f"Projets: {st.session_state.projects_created} | "
        f"Ex√©cutions: {st.session_state.code_executions} | "
        f"{theme_status}"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()