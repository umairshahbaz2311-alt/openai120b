"""
OpenAI 120B Advanced - Version SimplifiÃ©e et OptimisÃ©e
Interface complÃ¨te avec gÃ©nÃ©ration de code, exÃ©cution Python et projets
"""

import os
import streamlit as st
from openai import OpenAI
import time
import json
import datetime
from pathlib import Path
import sys
import io
import traceback
import zipfile
import re
import requests
import pandas as pd
from PIL import Image
import hashlib
from contextlib import redirect_stdout, redirect_stderr
from functools import lru_cache
from typing import Dict, List, Optional, Any
import uuid

# Configuration sÃ©curisÃ©e
SECURITY_CONFIG = {
    "max_execution_time": 10,
    "max_memory_mb": 100,
    "allowed_modules": {'math', 'datetime', 'json', 'random', 'time', 're', 'statistics', 'numpy', 'pandas'},
    "blocked_functions": {'exec', 'eval', 'open', '__import__', 'compile', 'memoryview'},
    "max_file_size_mb": 10,
    "max_project_files": 20
}

# Configuration de la page
st.set_page_config(
    page_title="OpenAI 120B Advanced",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# RÃ©pertoires
BASE_DIR = Path(".")
CONVERSATIONS_DIR = BASE_DIR / "conversations" 
GENERATED_PROJECTS_DIR = BASE_DIR / "generated_projects"
UPLOADS_DIR = BASE_DIR / "uploads"

# CrÃ©er les rÃ©pertoires
for directory in [CONVERSATIONS_DIR, GENERATED_PROJECTS_DIR, UPLOADS_DIR]:
    directory.mkdir(exist_ok=True)

# Fichiers de donnÃ©es
CHAT_HISTORY_FILE = BASE_DIR / "chat_history.json"
CREDITS_USAGE_FILE = BASE_DIR / "credits_usage.json"

# Initialisation des Ã©tats de session
def init_session_state():
    defaults = {
        'dark_mode': False,
        'messages': [],
        'session_tokens': 0,
        'session_requests': 0,
        'projects_created': 0,
        'code_executions': 0
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# CSS optimisÃ©
@st.cache_data
def get_optimized_css(dark_mode: bool) -> str:
    base_styles = """
    <style>
    .stApp { 
        transition: all 0.3s ease;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    }
    .main-header {
        font-size: clamp(2rem, 5vw, 3rem);
        font-weight: 800;
        text-align: center;
        margin: 1rem 0 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    .usage-card {
        padding: 1.5rem;
        border-radius: 12px;
        margin: 0.5rem 0;
        text-align: center;
        color: white;
        background: linear-gradient(135deg, #1565C0 0%, #0D47A1 100%);
        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    }
    .feature-badge {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.4rem 0.8rem;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: 600;
        margin: 0.2rem;
        display: inline-block;
        box-shadow: 0 2px 4px rgba(0,0,0,0.2);
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        text-align: center;
        border-left: 4px solid #667eea;
    }
    .code-result {
        background: #f6f8fa;
        border: 1px solid #e1e4e8;
        border-radius: 6px;
        padding: 1rem;
        margin: 1rem 0;
        font-family: 'Fira Code', monospace;
    }
    """
    
    if dark_mode:
        return base_styles + """
        .stApp { 
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%);
            color: #e0e6ed;
        }
        .metric-card {
            background: #16213e;
            color: #e0e6ed;
            border-left-color: #667eea;
        }
        .code-result {
            background: #0d1117;
            border-color: #30363d;
            color: #e6edf3;
        }
        """
    else:
        return base_styles

st.markdown(get_optimized_css(st.session_state.dark_mode), unsafe_allow_html=True)

# Utilitaires
@lru_cache(maxsize=256)
def estimate_tokens(text: str) -> int:
    return max(1, int(len(text.split()) * 1.3))

def secure_hash(data: str) -> str:
    return hashlib.sha256(data.encode()).hexdigest()[:16]

# Gestionnaire de fichiers
def load_json_file(filepath: Path, default=None):
    if filepath.exists():
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erreur lecture {filepath}: {e}")
    return default or {}

def save_json_file(filepath: Path, data):
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except Exception as e:
        st.error(f"Erreur sauvegarde {filepath}: {e}")

# Chargement des donnÃ©es
def load_chat_history():
    return load_json_file(CHAT_HISTORY_FILE, [])

def save_chat_history():
    save_json_file(CHAT_HISTORY_FILE, st.session_state.messages)

def load_credits_usage():
    return load_json_file(CREDITS_USAGE_FILE, {
        "total_tokens": 0,
        "total_requests": 0,
        "sessions": [],
        "projects_created": 0
    })

def save_credits_usage(data):
    save_json_file(CREDITS_USAGE_FILE, data)

# ExÃ©cuteur de code sÃ©curisÃ©
class SecureCodeExecutor:
    def __init__(self):
        self.safe_builtins = {
            'abs', 'all', 'any', 'bool', 'dict', 'enumerate', 'filter',
            'float', 'int', 'len', 'list', 'map', 'max', 'min', 'print',
            'range', 'round', 'sorted', 'str', 'sum', 'type', 'zip',
            'set', 'tuple', 'reversed', 'chr', 'ord'
        }
    
    def execute(self, code: str) -> Dict[str, Any]:
        if not code.strip():
            return {"success": False, "output": "", "error": "Code vide"}
        
        # VÃ©rifications sÃ©curitaires
        dangerous_patterns = [
            r'\b(exec|eval|compile|__import__)\s*\(',
            r'\bopen\s*\(',
            r'\bfile\s*\(',
            r'subprocess',
            r'os\.(system|popen|remove)',
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, code):
                return {"success": False, "output": "", "error": f"Code dangereux dÃ©tectÃ©: {pattern}"}
        
        if len(code) > 10000:
            return {"success": False, "output": "", "error": "Code trop long (max 10000 caractÃ¨res)"}
        
        try:
            # Environnement sÃ©curisÃ©
            safe_globals = {
                '__builtins__': {name: getattr(__builtins__, name) 
                               for name in self.safe_builtins if hasattr(__builtins__, name)}
            }
            
            # Modules autorisÃ©s
            for module in SECURITY_CONFIG['allowed_modules']:
                try:
                    safe_globals[module] = __import__(module)
                    if module == 'numpy':
                        safe_globals['np'] = safe_globals[module]
                    elif module == 'pandas':
                        safe_globals['pd'] = safe_globals[module]
                except ImportError:
                    continue
            
            # Redirection des sorties
            output_buffer = io.StringIO()
            error_buffer = io.StringIO()
            
            try:
                with redirect_stdout(output_buffer), redirect_stderr(error_buffer):
                    exec(code, safe_globals)
                
                output = output_buffer.getvalue()
                error = error_buffer.getvalue()
                
                return {
                    'success': True,
                    'output': output,
                    'error': error if error else None
                }
                
            except Exception as e:
                return {
                    "success": False,
                    "output": "",
                    "error": f"Erreur d'exÃ©cution: {str(e)}"
                }
                
        except Exception as e:
            return {"success": False, "output": "", "error": f"Erreur systÃ¨me: {str(e)}"}

# Gestionnaire de projets
def create_project_structure(project_data: Dict) -> tuple:
    """CrÃ©e la structure d'un projet"""
    try:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        project_name = project_data.get('name', 'project').replace(' ', '_').lower()
        project_name = re.sub(r'[^a-z0-9_]', '', project_name)
        
        project_path = GENERATED_PROJECTS_DIR / f"{project_name}_{timestamp}"
        project_path.mkdir(parents=True, exist_ok=True)
        
        created_files = []
        files = project_data.get('files', [])
        
        for file_info in files:
            if isinstance(file_info, dict) and 'name' in file_info and 'content' in file_info:
                file_path = project_path / file_info['name']
                file_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(file_info['content'])
                
                created_files.append(str(file_path.relative_to(GENERATED_PROJECTS_DIR)))
        
        return project_path, created_files
        
    except Exception as e:
        st.error(f"Erreur crÃ©ation projet: {e}")
        return None, []

def create_download_zip(project_path: Path) -> Optional[Path]:
    """CrÃ©e un ZIP tÃ©lÃ©chargeable"""
    try:
        zip_path = project_path.with_suffix('.zip')
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in project_path.rglob('*'):
                if file_path.is_file():
                    arcname = file_path.relative_to(project_path)
                    zipf.write(file_path, arcname)
        return zip_path
    except Exception as e:
        st.error(f"Erreur crÃ©ation ZIP: {e}")
        return None

# Gestionnaire de fichiers uploadÃ©s
def handle_file_upload(uploaded_file) -> Optional[str]:
    """Traite un fichier uploadÃ©"""
    if not uploaded_file:
        return None
    
    # VÃ©rification taille
    if uploaded_file.size > SECURITY_CONFIG['max_file_size_mb'] * 1024 * 1024:
        st.error(f"Fichier trop volumineux (max {SECURITY_CONFIG['max_file_size_mb']}MB)")
        return None
    
    file_ext = uploaded_file.name.split('.')[-1].lower()
    
    try:
        if file_ext in ['txt', 'py', 'js', 'html', 'css', 'md']:
            content = uploaded_file.getvalue().decode('utf-8')
            with st.expander(f"ğŸ“„ {uploaded_file.name}", expanded=False):
                st.code(content[:2000] + ("..." if len(content) > 2000 else ""), language=file_ext)
            return f"Fichier texte '{uploaded_file.name}' analysÃ© ({len(content)} caractÃ¨res)."
            
        elif file_ext in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
            image = Image.open(uploaded_file)
            st.image(image, caption=uploaded_file.name, width=400)
            return f"Image '{uploaded_file.name}' affichÃ©e ({image.size[0]}x{image.size[1]}px)."
            
        elif file_ext == 'csv':
            df = pd.read_csv(uploaded_file)
            st.dataframe(df.head(100))
            return f"CSV '{uploaded_file.name}': {len(df)} lignes, {len(df.columns)} colonnes."
            
        else:
            st.info(f"Type de fichier '{file_ext}' non supportÃ© pour prÃ©visualisation")
            return f"Fichier '{uploaded_file.name}' uploadÃ©."
            
    except Exception as e:
        st.error(f"Erreur traitement fichier: {e}")
        return None

# Client OpenAI
@st.cache_resource
def init_openai_client(token: str) -> OpenAI:
    return OpenAI(
        base_url="https://router.huggingface.co/v1",
        api_key=token,
        timeout=30.0
    )

# Prompts systÃ¨me simplifiÃ©s
def get_system_prompt(mode: str) -> str:
    prompts = {
        "ğŸ’¬ Chat": "Tu es un assistant IA avancÃ©, serviable et prÃ©cis. RÃ©ponds de maniÃ¨re claire et dÃ©taillÃ©e en franÃ§ais.",
        
        "ğŸ”§ Code": """Tu es un expert dÃ©veloppeur. GÃ©nÃ¨re du code complet et fonctionnel.

Pour crÃ©er des projets, utilise ce format JSON:
```json
{
  "name": "nom_du_projet",
  "description": "Description dÃ©taillÃ©e",
  "type": "web|desktop|mobile|api",
  "files": [
    {
      "name": "index.html",
      "content": "<!DOCTYPE html>...",
      "description": "Fichier principal"
    }
  ],
  "installation": "Instructions d'installation",
  "usage": "Instructions d'utilisation"
}
```

RÃ¨gles:
- Code complet et commentÃ©
- SÃ©curitÃ© et bonnes pratiques
- Design moderne et responsive""",
        
        "âš¡ Python": """Tu es un expert Python. Ã‰cris du code exÃ©cutable et sÃ»r.

Modules disponibles: math, datetime, json, random, time, re, statistics, numpy, pandas.
Utilise print() pour afficher les rÃ©sultats.
Ã‰vite les opÃ©rations dangereuses ou non autorisÃ©es.

Format:
1. Explication du problÃ¨me
2. Code Python complet et commentÃ©
3. Exemple d'utilisation si pertinent"""
    }
    return prompts.get(mode, prompts["ğŸ’¬ Chat"])

# Extraction des donnÃ©es
def extract_json_from_response(response: str) -> Optional[Dict]:
    """Extrait JSON de la rÃ©ponse"""
    try:
        json_pattern = r'```json\s*\n(.*?)\n```'
        matches = re.findall(json_pattern, response, re.DOTALL)
        
        for match in matches:
            try:
                return json.loads(match.strip())
            except json.JSONDecodeError:
                continue
        
        return None
    except:
        return None

def extract_code_blocks(response: str, language: str = "python") -> List[str]:
    """Extrait les blocs de code"""
    pattern = f"```{language}\\s*\\n(.*?)\\n```"
    return re.findall(pattern, response, re.DOTALL)

# Interface principale
def main():
    # Header
    st.markdown('<h1 class="main-header">ğŸ§  OpenAI 120B Advanced</h1>', 
                unsafe_allow_html=True)
    
    # Badges de fonctionnalitÃ©s
    st.markdown("""
    <div style="text-align: center; margin: 2rem 0;">
        <span class="feature-badge">ğŸ”¥ Code Generation</span>
        <span class="feature-badge">âš¡ Python Exec</span>
        <span class="feature-badge">ğŸ“ File Upload</span>
        <span class="feature-badge">ğŸŒ“ Dark Mode</span>
        <span class="feature-badge">ğŸ’¾ Persistent Chat</span>
        <span class="feature-badge">ğŸ”’ Secure Sandbox</span>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ›ï¸ Centre de ContrÃ´le")
        
        # Toggle thÃ¨me
        if st.button("ğŸŒ“ Basculer ThÃ¨me", key="theme_toggle"):
            st.session_state.dark_mode = not st.session_state.dark_mode
            st.rerun()
        
        theme_status = "ğŸŒ™ Mode Sombre" if st.session_state.dark_mode else "â˜€ï¸ Mode Clair"
        st.caption(f"ThÃ¨me actuel: {theme_status}")
        
        st.markdown("---")
        
        # Configuration token
        st.subheader("ğŸ” Configuration")
        user_token = st.text_input(
            "Token Hugging Face",
            type="password",
            placeholder="hf_...",
            help="Votre token HF pour accÃ©der Ã  l'API",
            key="hf_token_input"
        )
        
        if not user_token or not user_token.startswith("hf_"):
            st.warning("âš ï¸ Token HF requis (format: hf_...)")
            st.markdown("""
            **Comment obtenir votre token:**
            1. [CrÃ©er un compte HF](https://huggingface.co/join)
            2. Aller dans [Settings > Access Tokens](https://huggingface.co/settings/tokens)
            3. CrÃ©er un nouveau token (Read access)
            4. Copier et coller ici
            """)
            st.stop()
        
        st.success("âœ… Token dÃ©tectÃ©")
        
        # ParamÃ¨tres IA
        st.subheader("ğŸ¤– ParamÃ¨tres IA")
        work_mode = st.selectbox(
            "Mode de travail:",
            ["ğŸ’¬ Chat", "ğŸ”§ Code", "âš¡ Python"],
            key="work_mode"
        )
        
        temperature = st.slider("ğŸŒ¡ï¸ CrÃ©ativitÃ©", 0.1, 1.5, 0.7, 0.1)
        max_tokens = st.slider("ğŸ“ Tokens Max", 500, 4000, 2000, 250)
        
        # Options
        st.subheader("âš™ï¸ Options")
        auto_execute = st.checkbox("âš¡ Auto-exÃ©cution Python", value=True)
        auto_projects = st.checkbox("ğŸ“ Auto-crÃ©ation projets", value=True)
        
        # Upload de fichiers
        st.subheader("ğŸ“ Upload Fichiers")
        uploaded_file = st.file_uploader(
            "Choisir un fichier",
            type=['txt', 'py', 'js', 'html', 'css', 'md', 'csv', 'jpg', 'jpeg', 'png', 'pdf'],
            help="Fichiers supportÃ©s: texte, code, images, CSV"
        )
        
        # Statistiques de session
        st.subheader("ğŸ“Š Session")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Messages", len(st.session_state.messages))
            st.metric("Tokens", st.session_state.session_tokens)
        with col2:
            st.metric("RequÃªtes", st.session_state.session_requests)
            st.metric("Projets", st.session_state.projects_created)
        
        # Actions
        st.subheader("ğŸ› ï¸ Actions")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ—‘ï¸ Reset Chat", type="secondary"):
                st.session_state.messages = []
                save_chat_history()
                st.success("Chat rÃ©initialisÃ©!")
                time.sleep(1)
                st.rerun()
        
        with col2:
            if st.button("ğŸ’¾ Export") and st.session_state.messages:
                export_data = {
                    "messages": st.session_state.messages,
                    "metadata": {
                        "export_date": datetime.datetime.now().isoformat(),
                        "total_messages": len(st.session_state.messages),
                        "session_tokens": st.session_state.session_tokens
                    }
                }
                
                st.download_button(
                    "ğŸ“¥ TÃ©lÃ©charger Chat",
                    json.dumps(export_data, indent=2, ensure_ascii=False),
                    file_name=f"chat_export_{int(time.time())}.json",
                    mime="application/json"
                )
    
    # Initialisation du client OpenAI
    try:
        client = init_openai_client(user_token)
        st.success("âœ… Client OpenAI initialisÃ©")
    except Exception as e:
        st.error(f"âŒ Erreur client: {e}")
        st.stop()
    
    # Chargement de l'historique
    if not st.session_state.messages:
        st.session_state.messages = load_chat_history()
    
    # Gestionneurs
    executor = SecureCodeExecutor()
    
    # Zone de chat
    st.markdown("### ğŸ’¬ Chat avec Historique Persistant")
    
    # Affichage des messages
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # RÃ©sultats d'exÃ©cution Python
            if "execution_result" in message:
                result = message["execution_result"]
                with st.expander("âš¡ RÃ©sultat d'ExÃ©cution Python", expanded=True):
                    if result["success"]:
                        if result["output"]:
                            st.success("âœ… ExÃ©cution rÃ©ussie")
                            st.code(result["output"], language="text")
                        else:
                            st.info("âœ… Code exÃ©cutÃ© sans sortie")
                        if result.get("error"):
                            st.warning(f"âš ï¸ Avertissements: {result['error']}")
                    else:
                        st.error("âŒ Erreur d'exÃ©cution")
                        st.code(result["error"], language="text")
            
            # Projets crÃ©Ã©s
            if "project_created" in message:
                project_info = message["project_created"]
                with st.expander("ğŸš€ Projet CrÃ©Ã©", expanded=True):
                    st.success(f"âœ… **{project_info['name']}** crÃ©Ã©!")
                    st.markdown(f"**Description:** {project_info['description']}")
                    
                    if project_info.get('files'):
                        st.markdown("**ğŸ“ Fichiers crÃ©Ã©s:**")
                        for file_path in project_info['files']:
                            st.text(f"ğŸ“„ {file_path}")
    
    # Traitement du fichier uploadÃ©
    file_context = ""
    if uploaded_file:
        with st.spinner("Traitement du fichier..."):
            file_context = handle_file_upload(uploaded_file) or ""
    
    # Zone de saisie
    placeholder_texts = {
        "ğŸ’¬ Chat": "Posez votre question...",
        "ğŸ”§ Code": "DÃ©crivez l'application Ã  crÃ©er...",
        "âš¡ Python": "DÃ©crivez le calcul Ã  effectuer..."
    }
    
    if prompt := st.chat_input(placeholder_texts.get(work_mode, "Votre message...")):
        # Ajouter contexte du fichier si prÃ©sent
        full_prompt = f"{prompt}\n\n[Contexte fichier: {file_context}]" if file_context else prompt
        
        # Message utilisateur
        st.session_state.messages.append({"role": "user", "content": full_prompt})
        save_chat_history()
        
        with st.chat_message("user"):
            st.markdown(full_prompt)
        
        # GÃ©nÃ©ration de la rÃ©ponse
        with st.chat_message("assistant"):
            try:
                # PrÃ©paration des messages pour l'API
                system_prompt = get_system_prompt(work_mode)
                api_messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": full_prompt}
                ]
                
                # Ajout de l'historique rÃ©cent (limitÃ©)
                recent_messages = st.session_state.messages[-6:]
                for msg in recent_messages[:-1]:
                    if len(msg["content"]) < 1500:
                        api_messages.append({
                            "role": msg["role"],
                            "content": msg["content"][:1000] + ("..." if len(msg["content"]) > 1000 else "")
                        })
                
                # Appel API avec retry
                response = None
                with st.spinner("GÃ©nÃ©ration de la rÃ©ponse..."):
                    for attempt in range(3):
                        try:
                            completion = client.chat.completions.create(
                                model="openai/gpt-oss-120b:together",
                                messages=api_messages,
                                max_tokens=max_tokens,
                                temperature=temperature,
                            )
                            response = completion.choices[0].message.content
                            break
                        except Exception as e:
                            if attempt == 2:
                                raise e
                            time.sleep(1)
                
                if not response:
                    response = "âŒ Erreur: Impossible de gÃ©nÃ©rer une rÃ©ponse"
                
                # Affichage de la rÃ©ponse
                st.markdown(response)
                
                # PrÃ©paration des donnÃ©es du message
                message_data = {"role": "assistant", "content": response}
                
                # Post-traitement selon le mode
                if work_mode == "âš¡ Python" or auto_execute:
                    # ExÃ©cution automatique du code Python
                    python_blocks = extract_code_blocks(response, "python")
                    if python_blocks:
                        st.markdown("---")
                        st.markdown("### âš¡ ExÃ©cution Automatique du Code")
                        
                        for i, code_block in enumerate(python_blocks):
                            with st.expander(f"ğŸ Code Python {i+1}", expanded=True):
                                st.code(code_block, language="python")
                                
                                with st.spinner("ExÃ©cution en cours..."):
                                    result = executor.execute(code_block)
                                
                                message_data["execution_result"] = result
                                
                                if result["success"]:
                                    if result["output"]:
                                        st.success("âœ… ExÃ©cution rÃ©ussie")
                                        st.code(result["output"], language="text")
                                    else:
                                        st.info("âœ… Code exÃ©cutÃ© sans sortie")
                                    if result.get("error"):
                                        st.warning(f"âš ï¸ Avertissements: {result['error']}")
                                else:
                                    st.error("âŒ Erreur d'exÃ©cution")
                                    st.code(result["error"], language="text")
                        
                        st.session_state.code_executions += 1
                
                elif work_mode == "ğŸ”§ Code" or auto_projects:
                    # CrÃ©ation automatique de projets
                    project_data = extract_json_from_response(response)
                    if project_data and project_data.get('files'):
                        st.markdown("---")
                        st.markdown("### ğŸš€ CrÃ©ation du Projet")
                        
                        with st.spinner("CrÃ©ation du projet..."):
                            project_path, created_files = create_project_structure(project_data)
                        
                        if project_path and created_files:
                            message_data["project_created"] = {
                                "name": project_data.get("name", "Projet Sans Nom"),
                                "description": project_data.get("description", ""),
                                "files": created_files,
                                "path": str(project_path.relative_to(GENERATED_PROJECTS_DIR))
                            }
                            
                            st.success(f"âœ… Projet **{project_data.get('name')}** crÃ©Ã©!")
                            
                            # Affichage des fichiers
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**ğŸ“ Fichiers crÃ©Ã©s:**")
                                for file_path in created_files:
                                    st.text(f"ğŸ“„ {file_path}")
                            
                            with col2:
                                # Bouton de tÃ©lÃ©chargement
                                zip_path = create_download_zip(project_path)
                                if zip_path and zip_path.exists():
                                    with open(zip_path, 'rb') as f:
                                        st.download_button(
                                            "ğŸ“¥ TÃ©lÃ©charger Projet (ZIP)",
                                            f.read(),
                                            file_name=f"{project_data.get('name', 'project')}.zip",
                                            mime="application/zip"
                                        )
                            
                            st.session_state.projects_created += 1
                
                # Calcul des tokens et coÃ»t
                tokens_used = estimate_tokens(response)
                input_tokens = sum(estimate_tokens(msg["content"]) for msg in api_messages)
                total_tokens = tokens_used + input_tokens
                cost_estimate = total_tokens * 0.00075 / 1000  # Estimation du coÃ»t
                
                # MÃ©triques en bas
                st.markdown("---")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.caption(f"ğŸ“ {tokens_used} tokens sortie")
                with col2:
                    st.caption(f"ğŸ“Š {total_tokens} tokens total")
                with col3:
                    st.caption(f"ğŸ’° ~${cost_estimate:.4f}")
                with col4:
                    st.caption(f"ğŸ¯ {work_mode}")
                
                # Mise Ã  jour des compteurs de session
                st.session_state.session_tokens += total_tokens
                st.session_state.session_requests += 1
                
                # Sauvegarde des statistiques
                credits_data = load_credits_usage()
                credits_data['total_tokens'] = credits_data.get('total_tokens', 0) + total_tokens
                credits_data['total_requests'] = credits_data.get('total_requests', 0) + 1
                save_credits_usage(credits_data)
                
            except Exception as e:
                error_msg = f"âŒ Erreur: {str(e)}"
                st.error(error_msg)
                message_data = {"role": "assistant", "content": error_msg}
        
        # Sauvegarde du message
        st.session_state.messages.append(message_data)
        save_chat_history()
    
    # Guide d'utilisation si aucun message
    if not st.session_state.messages:
        st.markdown("""
        ## ğŸ¯ Guide d'Utilisation OpenAI 120B Advanced
        
        ### ğŸ†• **FonctionnalitÃ©s Disponibles**
        - âš¡ **ExÃ©cution Python SÃ©curisÃ©e** - Code exÃ©cutÃ© dans un sandbox
        - ğŸš€ **GÃ©nÃ©ration de Projets** - Applications complÃ¨tes tÃ©lÃ©chargeables
        - ğŸ’¾ **Chat Persistant** - Historique sauvegardÃ© automatiquement
        - ğŸ“ **Upload Fichiers** - Support images, CSV, code
        - ğŸŒ“ **Mode Sombre/Clair** - Interface adaptable
        - ğŸ”’ **SÃ©curitÃ© RenforcÃ©e** - Validation stricte du code
        
        ### âš¡ **Exemples Python**
        - *"Analyse ce fichier CSV uploadÃ©"*
        - *"CrÃ©e un graphique des donnÃ©es de vente"*
        - *"Calcule les statistiques de ce dataset: [1,2,3,4,5]"*
        - *"GÃ©nÃ¨re 10 nombres alÃ©atoires et calcule leur moyenne"*
        
        ### ğŸ”§ **Exemples Projets**
        - *"DÃ©veloppe une todo-list en HTML/CSS/JS"*
        - *"CrÃ©e une calculatrice web moderne"*
        - *"GÃ©nÃ¨re un site portfolio responsive"*
        - *"Fais une API REST Flask simple"*
        
        ### ğŸ’¬ **Chat GÃ©nÃ©ral**
        - Questions techniques avec contexte
        - Analyse de fichiers uploadÃ©s
        - Explications dÃ©taillÃ©es
        - Conseils et recommandations
        
        **ğŸš€ Commencez par uploader un fichier ou poser une question !**
        """)
    
    # Footer avec statistiques
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("**ğŸ§  OpenAI 120B**")
        st.caption("Assistant IA AvancÃ©")
    
    with col2:
        st.markdown("**âš¡ Python**")
        st.caption("ExÃ©cution sÃ©curisÃ©e")
    
    with col3:
        st.markdown("**ğŸš€ Projets**")
        st.caption(f"{st.session_state.projects_created} crÃ©Ã©s")
    
    with col4:
        st.markdown("**ğŸ’¾ Session**")
        st.caption(f"{len(st.session_state.messages)} messages")
    
    # Version et informations
    st.markdown(
        f"<div style='text-align: center; color: #666; font-size: 0.8rem; margin-top: 1rem;'>"
        f"ğŸ’¡ Version 4.0 SimplifiÃ© | Session: {st.session_state.session_tokens} tokens | "
        f"Projets: {st.session_state.projects_created} | "
        f"ExÃ©cutions: {st.session_state.code_executions} | "
        f"{theme_status}"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()